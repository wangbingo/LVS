{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mmaction_installation_finish_201909202206.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangbingo/LVS/blob/master/mmaction_installation_finish_201909202206.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCJrRgfk26Hy",
        "colab_type": "text"
      },
      "source": [
        "installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FWwTBc81d_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --recursive https://github.com/open-mmlab/mmaction.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9UjuIHm3RMr",
        "colab_type": "text"
      },
      "source": [
        "Install Pre-requisites.\n",
        "Install Decord (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgkW2pXa3hpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install -y software-properties-common"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "340qRbhI36P7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo add-apt-repository ppa:jonathonf/ffmpeg-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TRfEtLl4Kda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJL8lH764Z7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install -y build-essential python3-dev python3-setuptools make cmake libavcodec-dev libavfilter-dev libavformat-dev libavutil-dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pw12e5B6bPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJjArtyO62kX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd mmaction/third_party/decord && mkdir build && cd build && cmake .. -DUSE_CUDA=0 && make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqyGuAvY8rqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd mmaction/third_party/decord/python/  &&  python setup.py install --user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSH4kbQX9wwC",
        "colab_type": "text"
      },
      "source": [
        "Install MMAction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHiv-tle9SAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "073f394c-6b73-4636-a7cc-5482a31d1294"
      },
      "source": [
        "!pip install cython"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeESA3HK-FPO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "156777f5-2b2a-4075-ca6c-3966deb9b4c6"
      },
      "source": [
        "!cd mmaction/  && sh  ./compile.sh"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building package resample2d\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating resample2d_cuda.egg-info\n",
            "writing resample2d_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to resample2d_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to resample2d_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'resample2d_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'resample2d_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c resample2d_cuda.cc -o build/temp.linux-x86_64-3.6/resample2d_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Kresample2d_cuda.cc:2:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c resample2d_kernel.cu -o build/temp.linux-x86_64-3.6/resample2d_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=resample2d_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/resample2d_cuda.o build/temp.linux-x86_64-3.6/resample2d_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/resample2d_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/resample2d_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for resample2d_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/resample2d_cuda.py to resample2d_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying resample2d_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.resample2d_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "Adding resample2d-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for resample2d-cuda==0.0.0\n",
            "Finished processing dependencies for resample2d-cuda==0.0.0\n",
            "Building package trajectory_conv...\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating traj_conv_cuda.egg-info\n",
            "writing traj_conv_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to traj_conv_cuda.egg-info/dependency_links.txt\n",
            "writing top-level names to traj_conv_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'traj_conv_cuda.egg-info/SOURCES.txt'\n",
            "writing manifest file 'traj_conv_cuda.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'traj_conv_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c traj_conv_cuda.cpp -o build/temp.linux-x86_64-3.6/traj_conv_cuda.o -std=c++11 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=traj_conv_cuda -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[Ktraj_conv_cuda.cpp:2:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:7:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Including torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ktraj_conv_cuda.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kint deform_3d_conv_forward_cuda(at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, at::Tensor&, int, int, int, int, int, int, int, int, int, int, int, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ktraj_conv_cuda.cpp:127:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kbatch\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "   int \u001b[01;35m\u001b[Kbatch\u001b[m\u001b[K = 1;\n",
            "       \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c deform_3d_conv_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/deform_3d_conv_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_70,code=compute_70 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=traj_conv_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "\u001b[01m\u001b[Kdeform_3d_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kdeform_3d_conv_cuda_kernel.cu:244:124:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdeform_3d_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kdeform_3d_conv_cuda_kernel.cu:344:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(data_col.type(), \"deformable_col2im_kernel\", ([&] {\n",
            "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kdeform_3d_conv_cuda_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Kdeform_3d_conv_cuda_kernel.cu:447:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(data_col.type(), \"deformable_col2im_coord_kernel\", ([&] {\n",
            "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/traj_conv_cuda.o build/temp.linux-x86_64-3.6/deform_3d_conv_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/traj_conv_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.6/traj_conv_cuda.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for traj_conv_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/traj_conv_cuda.py to traj_conv_cuda.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_conv_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_conv_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_conv_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying traj_conv_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.traj_conv_cuda.cpython-36: module references __file__\n",
            "creating dist\n",
            "creating 'dist/traj_conv_cuda-0.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing traj_conv_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.6/site-packages/traj_conv_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Extracting traj_conv_cuda-0.0.0-py3.6-linux-x86_64.egg to /root/.local/lib/python3.6/site-packages\n",
            "Adding traj-conv-cuda 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.6/site-packages/traj_conv_cuda-0.0.0-py3.6-linux-x86_64.egg\n",
            "Processing dependencies for traj-conv-cuda==0.0.0\n",
            "Finished processing dependencies for traj-conv-cuda==0.0.0\n",
            "Building roi align op...\n",
            "running build_ext\n",
            "building 'roi_align_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/src\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c src/roi_align_cuda.cpp -o build/temp.linux-x86_64-3.6/src/roi_align_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=roi_align_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c src/roi_align_kernel.cu -o build/temp.linux-x86_64-3.6/src/roi_align_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=roi_align_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "\u001b[01m\u001b[Ksrc/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ksrc/roi_align_kernel.cu:133:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/roi_align_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ksrc/roi_align_kernel.cu:276:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/src/roi_align_cuda.o build/temp.linux-x86_64-3.6/src/roi_align_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/roi_align_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/roi_align_cuda.cpython-36m-x86_64-linux-gnu.so -> \n",
            "Building roi pool op...\n",
            "running build_ext\n",
            "building 'roi_pool_cuda' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/src\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c src/roi_pool_cuda.cpp -o build/temp.linux-x86_64-3.6/src/roi_pool_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=roi_pool_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c src/roi_pool_kernel.cu -o build/temp.linux-x86_64-3.6/src/roi_pool_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=roi_pool_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(83): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lowest\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(84): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"max\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(85): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"lower_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/include/ATen/cuda/NumericLimits.cuh(86): warning: calling a constexpr __host__ function(\"from_bits\") from a __host__ __device__ function(\"upper_bound\") is not allowed. The experimental flag '--expt-relaxed-constexpr' can be used to allow this.\n",
            "\n",
            "\u001b[01m\u001b[Ksrc/roi_pool_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ksrc/roi_pool_kernel.cu:88:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/roi_pool_kernel.cu:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[Ksrc/roi_pool_kernel.cu:136:126:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(\n",
            "                                                                                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " \u001b[01;36m\u001b[Kinline at::\u001b[m\u001b[KScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            " \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/src/roi_pool_cuda.o build/temp.linux-x86_64-3.6/src/roi_pool_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/roi_pool_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/roi_pool_cuda.cpython-36m-x86_64-linux-gnu.so -> \n",
            "Building nms op...\n",
            "running build_ext\n",
            "building 'soft_nms_cpu' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.6\n",
            "creating build/temp.linux-x86_64-3.6/src\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/numpy/core/include -I/usr/include/python3.6m -c src/soft_nms_cpu.cpp -o build/temp.linux-x86_64-3.6/src/soft_nms_cpu.o -Wno-unused-function -Wno-write-strings\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/soft_nms_cpu.cpp:655\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/soft_nms_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_12soft_nms_cpu_soft_nms_cpu(PyObject*, PyArrayObject*, float, unsigned int, float, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/soft_nms_cpu.cpp:2483:34:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_10 = ((\u001b[01;35m\u001b[K__pyx_v_pos < __pyx_v_N\u001b[m\u001b[K) != 0);\n",
            "                      \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/soft_nms_cpu.cpp:2994:34:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "       __pyx_t_10 = ((\u001b[01;35m\u001b[K__pyx_v_pos < __pyx_v_N\u001b[m\u001b[K) != 0);\n",
            "                      \u001b[01;35m\u001b[K~~~~~~~~~~~~^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/src/soft_nms_cpu.o -o /content/mmaction/mmaction/ops/nms/soft_nms_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "running build_ext\n",
            "building 'nms_cuda' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c src/nms_cuda.cpp -o build/temp.linux-x86_64-3.6/src/nms_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nms_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c src/nms_kernel.cu -o build/temp.linux-x86_64-3.6/src/nms_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nms_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "creating build/lib.linux-x86_64-3.6\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/src/nms_cuda.o build/temp.linux-x86_64-3.6/src/nms_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/nms_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "building 'nms_cpu' extension\n",
            "x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c src/nms_cpu.cpp -o build/temp.linux-x86_64-3.6/src/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=nms_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Ksrc/nms_cpu.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Ksrc/nms_cpu.cpp:\u001b[m\u001b[K In lambda function:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:71:52:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kc10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n",
            "     at::ScalarType _st = ::detail::scalar_type(TYPE\u001b[01;35m\u001b[K)\u001b[m\u001b[K;                        \\\n",
            "                                                    \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/nms_cpu.cpp:63:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro ‘\u001b[01m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K’\n",
            "   \u001b[01;36m\u001b[KAT_DISPATCH_FLOATING_TYPES\u001b[m\u001b[K(dets.type(), \"nms\", [&] {\n",
            "   \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:47:23:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            " inline at::ScalarType \u001b[01;36m\u001b[Kscalar_type\u001b[m\u001b[K(const at::DeprecatedTypeProperties &t) {\n",
            "                       \u001b[01;36m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/src/nms_cpu.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/nms_cpu.cpython-36m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.6/nms_cuda.cpython-36m-x86_64-linux-gnu.so -> \n",
            "copying build/lib.linux-x86_64-3.6/nms_cpu.cpython-36m-x86_64-linux-gnu.so -> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sm7rnPy_K4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6a1bddd-72f0-4838-c4bd-db4cc30a9124"
      },
      "source": [
        "!cd mmaction/  &&  python setup.py develop"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/setuptools/dist.py:474: UserWarning: Normalizing '0.1.rc0+5f0e93f' to '0.1rc0+5f0e93f'\n",
            "  normalized_version,\n",
            "running develop\n",
            "running egg_info\n",
            "creating mmaction.egg-info\n",
            "writing mmaction.egg-info/PKG-INFO\n",
            "writing dependency_links to mmaction.egg-info/dependency_links.txt\n",
            "writing requirements to mmaction.egg-info/requires.txt\n",
            "writing top-level names to mmaction.egg-info/top_level.txt\n",
            "writing manifest file 'mmaction.egg-info/SOURCES.txt'\n",
            "writing manifest file 'mmaction.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.6/dist-packages/mmaction.egg-link (link to .)\n",
            "Adding mmaction 0.1rc0+5f0e93f to easy-install.pth file\n",
            "\n",
            "Installed /content/mmaction\n",
            "Processing dependencies for mmaction==0.1rc0+5f0e93f\n",
            "Searching for terminaltables\n",
            "Reading https://pypi.org/simple/terminaltables/\n",
            "Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz#sha256=f3eb0eb92e3833972ac36796293ca0906e998dc3be91fbe1f8615b331b853b81\n",
            "Best match: terminaltables 3.1.0\n",
            "Processing terminaltables-3.1.0.tar.gz\n",
            "Writing /tmp/easy_install-6whbs3px/terminaltables-3.1.0/setup.cfg\n",
            "Running terminaltables-3.1.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-6whbs3px/terminaltables-3.1.0/egg-dist-tmp-a0qk6q09\n",
            "Moving terminaltables-3.1.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding terminaltables 3.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/terminaltables-3.1.0-py3.6.egg\n",
            "Searching for mmcv\n",
            "Reading https://pypi.org/simple/mmcv/\n",
            "Downloading https://files.pythonhosted.org/packages/86/98/2db09740465707361f363f8644c71c98d0d9fe28c1f2e5821f8c5a4ee5ba/mmcv-0.2.13.tar.gz#sha256=edd7b221641333e01c2ad4301a1b80ee0f69166e0666fd2aca6b9898c995a197\n",
            "Best match: mmcv 0.2.13\n",
            "Processing mmcv-0.2.13.tar.gz\n",
            "Writing /tmp/easy_install-14urks0q/mmcv-0.2.13/setup.cfg\n",
            "Running mmcv-0.2.13/setup.py -q bdist_egg --dist-dir /tmp/easy_install-14urks0q/mmcv-0.2.13/egg-dist-tmp-jwlslnbe\n",
            "/usr/local/lib/python3.6/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /tmp/easy_install-14urks0q/mmcv-0.2.13/mmcv/video/optflow_warp/flow_warp_module.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1822:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/arrayobject.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./mmcv/video/optflow_warp/flow_warp_module.cpp:612\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.6/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K-Wcpp\u001b[m\u001b[K]\n",
            " #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "creating /usr/local/lib/python3.6/dist-packages/mmcv-0.2.13-py3.6-linux-x86_64.egg\n",
            "Extracting mmcv-0.2.13-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding mmcv 0.2.13 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mmcv-0.2.13-py3.6-linux-x86_64.egg\n",
            "Searching for addict\n",
            "Reading https://pypi.org/simple/addict/\n",
            "Downloading https://files.pythonhosted.org/packages/14/6f/beb258220417c1a0fe11e842f2e012a1be7eeeaa72a1d10ba17a804da367/addict-2.2.1-py3-none-any.whl#sha256=1948c2a5d93ba6026eb91aef2c971234aaf72488a9c07ab8a7950f82ae30eea7\n",
            "Best match: addict 2.2.1\n",
            "Processing addict-2.2.1-py3-none-any.whl\n",
            "Installing addict-2.2.1-py3-none-any.whl to /usr/local/lib/python3.6/dist-packages\n",
            "Adding addict 2.2.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/addict-2.2.1-py3.6.egg\n",
            "Searching for joblib==0.13.2\n",
            "Best match: joblib 0.13.2\n",
            "Adding joblib 0.13.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lmdb==0.97\n",
            "Best match: lmdb 0.97\n",
            "Adding lmdb 0.97 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scikit-learn==0.21.3\n",
            "Best match: scikit-learn 0.21.3\n",
            "Adding scikit-learn 0.21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.3.1\n",
            "Best match: scipy 1.3.1\n",
            "Adding scipy 1.3.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.5\n",
            "Best match: numpy 1.16.5\n",
            "Adding numpy 1.16.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Cython==0.29.13\n",
            "Best match: Cython 0.29.13\n",
            "Adding Cython 0.29.13 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for opencv-python==3.4.5.20\n",
            "Best match: opencv-python 3.4.5.20\n",
            "Adding opencv-python 3.4.5.20 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for requests==2.21.0\n",
            "Best match: requests 2.21.0\n",
            "Adding requests 2.21.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for PyYAML==3.13\n",
            "Best match: PyYAML 3.13\n",
            "Adding PyYAML 3.13 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for idna==2.8\n",
            "Best match: idna 2.8\n",
            "Adding idna 2.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for certifi==2019.6.16\n",
            "Best match: certifi 2019.6.16\n",
            "Adding certifi 2019.6.16 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for mmaction==0.1rc0+5f0e93f\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}